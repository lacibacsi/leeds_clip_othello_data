{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wVYiTjXVqqO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZTEDs8WVrlE"
      },
      "source": [
        "## Othello clip training notebook\n",
        "to use Google's larger machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUH4RC2TVwGi"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os.path\n",
        "import time\n",
        "\n",
        "import clip\n",
        "import data_handling\n",
        "from clip import inference\n",
        "from clip.inference import ClipInference\n",
        "from clip.model import CLIPModel\n",
        "#from data_handling.clip_data_prep import ClipDataPreparator\n",
        "#from data_handling.game_parser import GameParser\n",
        "#from data_handling.book_parser import BookParser\n",
        "#from data_handling.common import convert_to_notation\n",
        "import torch\n",
        "from othello_game import othello\n",
        "import data_handling.common as cm\n",
        "#from clip.train import ClipTrainer\n",
        "from clip import utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4u1ILyyYOch"
      },
      "outputs": [],
      "source": [
        "def play_game():\n",
        "    # plays a sample game of othello based on the move string\n",
        "\n",
        "    cols = \"ABCDEFGH\"\n",
        "\n",
        "    #moves = \"f5d6c4d3e6f4e3f6c5b4e7f3c6d7b5a5c3b3g5h5g4h4e2g6b6d8c7c8a4a6a7f1a3c2d2b2e1b7g3h3f2d1a1a2b1a8c1g1f7g8e8f8b8g7h8h7h6h2g2h1\"\n",
        "    moves = 'E3F2E2D2E1F6D3D6G4G3G5H3E6H4H6G6F7E7D7F1H5H7G1C8G2F3C6D8E8C5B5F8C7B4B6C3A3B8C2C4B3B2G7A4A1A5B7A2A6D1B1C1H2H8G8H1A8A7'\n",
        "    moves = 'E6F4C3C4F3D3E3E2E1D2C5G3H3C2D1C1B1B3A3B4G6F2A4B5A5A6A7B6F1G4H4D6C6B2A1A2A8B7B8C8C7D7D8E8E7F8F7G8H8G7H7G5H6H5H2G2G1H1'\n",
        "    game = othello.OthelloGame(8, 8, 'B', 'W', 'M')\n",
        "\n",
        "    allmoves = [moves[i:i +2] for i in range(0, len(moves), 2)]\n",
        "    for move in allmoves:\n",
        "        # notation is column + row, the game takes them separately\n",
        "        row = int(move[1])-1\n",
        "        column = int(cols.index(str.upper(move[0])))\n",
        "        game.move(row, column)\n",
        "\n",
        "    print(f'game played, final board: {game.current_board}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiiJjxKyYb7C"
      },
      "outputs": [],
      "source": [
        "def run_inference(model_file: str, eval_set: str):\n",
        "\n",
        "    inference = ClipInference(model_file)\n",
        "\n",
        "    result = inference.run_eval_file(eval_set)\n",
        "    print(result)\n",
        "    for p in result:\n",
        "        print(result[p][2])\n",
        "\n",
        "    # test validity of moves\n",
        "    validity_result = inference.run_validity_check(result)\n",
        "    print(validity_result)\n",
        "    for r in validity_result:\n",
        "        print(f'{validity_result[r][2]},{validity_result[r][3]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN463oHccuTe"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ToTensor:\n",
        "    # Convert pd series to Tensors\n",
        "    def __call__(self, sample):\n",
        "\n",
        "        stringboard = sample['board'].to_list()[0]\n",
        "        board_array = common.convert_board_array(stringboard)\n",
        "        board = torch.FloatTensor(board_array)\n",
        "\n",
        "        move = sample['move'].to_list()[0]\n",
        "        move = common.convert_move_to_tensor(move)\n",
        "\n",
        "        return board, move\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJbRpau4cyAL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class ClipDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.__df__ = df\n",
        "        self.length = len(df)\n",
        "        self.transform = ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.__df__.iloc[[idx]]\n",
        "\n",
        "        board, move = self.transform(row)\n",
        "        item = {}\n",
        "        item['board'] = board\n",
        "        item['move'] = move\n",
        "\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plb6SYu7c3jH"
      },
      "outputs": [],
      "source": [
        "from clip.meter import AvgMeter\n",
        "from tqdm import tqdm\n",
        "from data_handling import common\n",
        "\n",
        "class ClipTrainer:\n",
        "    '''\n",
        "    Trains the clip model based on the input variables, parameters and config\n",
        "    '''\n",
        "\n",
        "    def __init__(self, source_path: str):\n",
        "        self.source_path = source_path\n",
        "        self.source = None\n",
        "\n",
        "    def __read_source__(self):\n",
        "        '''\n",
        "        reads the source data from file into a dataframe\n",
        "        :return: None\n",
        "        '''\n",
        "        self.source = cm.read_dataframe(self.source_path)\n",
        "\n",
        "    def make_train_validation_sets(self, split=0.2) :\n",
        "        '''\n",
        "        creates train and validation dataframes from the source data\n",
        "        :param split: ration of validation set\n",
        "        :return: dataframes for train and validation respectively\n",
        "        '''\n",
        "        if self.source is None:\n",
        "            self.__read_source__()\n",
        "\n",
        "        # there is no 'id' in the dataset, so train / validation split happens on a shuffled dataset\n",
        "        # for large datasets this can take very long, TODO: optimize if need to rerun often\n",
        "        df = self.source.sample(frac=1, random_state=42)\n",
        "\n",
        "        split_index = int((1-split)*len(df))\n",
        "\n",
        "        train, val = df[:split_index], df[split_index:]\n",
        "        return train, val\n",
        "\n",
        "    def getLoader(self, dataframe: pd.DataFrame, mode: str) -> DataLoader:\n",
        "        '''\n",
        "        creates a data loader for the frame for training\n",
        "        :param dataframe:\n",
        "        :param mode: 'Train' or 'Val'\n",
        "        :return: torch dataloader\n",
        "        '''\n",
        "\n",
        "        ds = ClipDataset(dataframe)\n",
        "        loader = DataLoader(ds,\n",
        "                            batch_size=8,\n",
        "                            num_workers=12,\n",
        "                            shuffle=True if mode == 'Train' else False,\n",
        "        )\n",
        "\n",
        "        return loader\n",
        "\n",
        "\n",
        "# other static methods for training\n",
        "def train_epoch(device, model, train_loader, optimizer, lr_scheduler, step):\n",
        "    loss_meter = AvgMeter()\n",
        "    tqdm_object = tqdm(train_loader, total=len(train_loader))\n",
        "    for batch in tqdm_object:\n",
        "\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        loss = model(batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step == \"batch\":\n",
        "            lr_scheduler.step()\n",
        "\n",
        "        count = batch[\"board\"].size(0)\n",
        "        loss_meter.update(loss.item(), count)\n",
        "\n",
        "        tqdm_object.set_postfix(train_loss=loss_meter.avg, lr=clip.utils.get_lr(optimizer))\n",
        "    return loss_meter\n",
        "\n",
        "def valid_epoch(device, model, valid_loader):\n",
        "    loss_meter = AvgMeter()\n",
        "\n",
        "    tqdm_object = tqdm(valid_loader, total=len(valid_loader))\n",
        "    for batch in tqdm_object:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        loss = model(batch)\n",
        "\n",
        "        count = batch[\"board\"].size(0)\n",
        "        loss_meter.update(loss.item(), count)\n",
        "\n",
        "        tqdm_object.set_postfix(valid_loss=loss_meter.avg)\n",
        "    return loss_meter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoiZewYqYXwz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_clip_model(source_file: str):\n",
        "\n",
        "    trainer = ClipTrainer(source_file)\n",
        "    df_train, df_val = trainer.make_train_validation_sets()\n",
        "\n",
        "    # creating data loader\n",
        "    train_loader = trainer.getLoader(df_train, 'Train')\n",
        "    val_loader = trainer.getLoader(df_val, 'Val')\n",
        "\n",
        "    model = CLIPModel().to(utils.get_device())\n",
        "\n",
        "    print(f'model: {model}')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        #model.parameters(), lr=1e-3, weight_decay=1e-3\n",
        "        model.parameters(), lr=0.1, weight_decay=1e-3\n",
        "    )\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"min\", patience=2, factor=0.5\n",
        "    )\n",
        "    step = \"epoch\"\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    epochs_count = 6\n",
        "\n",
        "    for epoch in range(epochs_count):\n",
        "        print(f\"Epoch: {epoch + 1}\")\n",
        "        model.train()\n",
        "        train_loss = train_epoch(utils.get_device(), model, train_loader, optimizer, lr_scheduler, step)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            valid_loss = valid_epoch(utils.get_device(), model, val_loader)\n",
        "\n",
        "        if valid_loss.avg < best_loss:\n",
        "            best_loss = valid_loss.avg\n",
        "            torch.save(model.state_dict(), os.path.join(data_handling.common.DEFAULT_MODEL_OUTPUT_PATH,\"best.pt\"))\n",
        "            print(\"Saved Best Model!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMHzfqvKYkAI",
        "outputId": "90b43ff9-7ac2-4634-d27b-ca4fe897e93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "model: CLIPModel(\n",
            "  (image_encoder): ImageEncoder(\n",
            "    (conv1): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act1): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act2): ReLU(inplace=True)\n",
            "    (av1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (fc1): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (text_encoder): TextEncoder()\n",
            "  (image_projection): ProjectionHead(\n",
            "    (projection): Linear(in_features=1024, out_features=64, bias=True)\n",
            "    (gelu): GELU(approximate='none')\n",
            "    (fc): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (text_projection): ProjectionHead(\n",
            "    (projection): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (gelu): GELU(approximate='none')\n",
            "    (fc): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1680952/1680952 [3:19:28<00:00, 140.44it/s, lr=0.1, train_loss=2.64]\n",
            "100%|██████████| 420238/420238 [29:40<00:00, 236.09it/s, valid_loss=2.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best Model!\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1680952/1680952 [3:25:28<00:00, 136.35it/s, lr=0.1, train_loss=2.88]\n",
            "100%|██████████| 420238/420238 [30:06<00:00, 232.60it/s, valid_loss=2.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1680952/1680952 [3:27:21<00:00, 135.11it/s, lr=0.1, train_loss=2.9]\n",
            "100%|██████████| 420238/420238 [30:14<00:00, 231.55it/s, valid_loss=2.08]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1603217/1680952 [3:15:38<09:19, 138.94it/s, lr=0.1, train_loss=2.87]"
          ]
        }
      ],
      "source": [
        "print(utils.get_device())\n",
        "train_clip_model('/content/clip_training_source')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQiyd6NMYqn0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}